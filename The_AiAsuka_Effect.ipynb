{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1I36dN1eoXt30g6mjubH92IcNWQnebO6Z",
      "authorship_tag": "ABX9TyPHeZaZLDaGnetIkddOW/FL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YamaMaki/aiasuka-data-project/blob/main/The_AiAsuka_Effect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Aiasuka Effect: A Case Study on Gender Bias in Web3\n",
        "\n",
        "## 1. Objective & Hypothesis\n",
        "\n",
        "This case study investigates how gender identityâ€”specifically a synthetic feminine personaâ€”affects engagement and follower growth on X in the male-dominated Web3 space. By deploying \"Aiasuka,\" an AI-generated persona, and bookending the experiment with authentic identity posts, it examines gender bias, parasocial attachment, and the ethical risks of synthetic personas displacing real female voices.\n",
        "\n",
        "An AI-generated feminine persona will significantly increase engagement and follower growth through parasocial attraction and gender bias, even if suspected to be artificial. Reverting to an authentic male identity will reveal the fragility of these bonds, highlighting perceived genderâ€™s dominance over authentic identity."
      ],
      "metadata": {
        "id": "Y-Pzxe5oKmkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Loading & Cleaning\n",
        "\n",
        "In this section, we load the raw data from a multi-tab Google Sheet. We then perform a series of data cleaning and standardization stepsâ€”including cleaning column names, consolidating redundant columns, and handling missing valuesâ€”to create a single, unified DataFrame that is ready for analysis."
      ],
      "metadata": {
        "id": "g6yP1m8-Kw6a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEf5AdPHbtWw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "google_sheet_url = 'https://docs.google.com/spreadsheets/d/1TW7VnSh1zak52d5IpG7pUgxwjK1VJAvEVaPb918O_dE/export?format=xlsx'\n",
        "\n",
        "# read all tabs into a dictionary of DataFrames\n",
        "all_tabs = pd.read_excel(google_sheet_url, sheet_name=None)\n",
        "\n",
        "# Combine all DataFrames into one master DataFrame\n",
        "master_df = pd.concat(all_tabs.values(), ignore_index=True)\n",
        "\n",
        "# Print the combined DataFrame\n",
        "print(\"--- Successfully loaded and combined DataFrame ---\")\n",
        "print(master_df.head())\n",
        "print(\"\\n--- Checking the 'Phase' column values ---\")\n",
        "print(master_df['Phase'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"--- 1. Overall DataFrame Info ---\")\n",
        "# This will show us all the column names, and how many non-null values are in each.\n",
        "master_df.info()\n",
        "\n",
        "print(\"\\n\\n--- 2. Count of Missing Values per Column ---\")\n",
        "# This gives a direct count of how many NaN values are in each column.\n",
        "# We expect to see a lot here because of the different column structures.\n",
        "print(master_df.isnull().sum())\n",
        "\n",
        "print(\"\\n\\n--- 3. Let's Look at the Column Names ---\")\n",
        "# This will show us all the column names so we can spot inconsistencies.\n",
        "print(master_df.columns)"
      ],
      "metadata": {
        "id": "h4tngVFkd-ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Original Column Names ---\")\n",
        "print(master_df.columns)\n",
        "\n",
        "#we will now go and apply a series of cleaning steps to each column name\n",
        "new_columns = master_df.columns\n",
        "new_columns = new_columns.str.lower() # 1. convert to lowercase\n",
        "new_columns = new_columns.str.replace(' ', '_') # 2. Replace spaces with underscores\n",
        "new_columns = new_columns.str.replace('(y/n)', '', regex=False) #3. remove (y/n)\n",
        "new_columns = new_columns.str.replace('(%)', '_pct', regex=False) # 4. replace (%) with _pct\n",
        "new_columns = new_columns.str.replace('.', '_', regex=False) #5. replace . with _\n",
        "master_df.columns = new_columns\n",
        "\n",
        "print(\"\\n--- Updated Column Names ---\")\n",
        "print(master_df.columns)\n",
        "\n",
        "print(\"\\n--- DataFrame Head with Clean Columns\")\n",
        "print(master_df.head())"
      ],
      "metadata": {
        "id": "dBRs3Y4bekL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see what's inside the two post_type columns\n",
        "\n",
        "print(\"--- Investigating 'post_type' column ---\")\n",
        "print(master_df['post_type'].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\n\\n--- Investigating 'post_type_1' column ---\")\n",
        "print(master_df['post_type_1'].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "A5MLtn6qgzyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Investigating ALL Post Category Columns ---\")\n",
        "\n",
        "print(\"\\n--- Column: 'post_type' (Cleaned) ---\")\n",
        "# We already cleaned this one, so the output should look good\n",
        "print(master_df['post_type'].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\n--- Column: 'post_format' ---\")\n",
        "# This is the one we just discovered from the other sheet\n",
        "print(master_df['post_format'].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\n--- Column: 'post_type_1' ---\")\n",
        "# This was the other one we found\n",
        "print(master_df['post_type_1'].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "xJp_R3MshsfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Complete Data Unification Script ---\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Coalesce the two descriptive columns ('post_format' and 'post_type_1')\n",
        "# This creates a new column, filling NaN values in the first with values from the second.\n",
        "master_df['temp_category'] = master_df['post_format'].combine_first(master_df['post_type_1'])\n",
        "\n",
        "print(\"--- Step 1 Complete: Combined the two descriptive columns. ---\")\n",
        "\n",
        "\n",
        "# Step 2: Standardize the new combined category column\n",
        "# We write a custom function to clean up all the messy, inconsistent text.\n",
        "\n",
        "def standardize_post_type(category):\n",
        "    # First, handle any potential missing values that might still exist\n",
        "    if pd.isnull(category):\n",
        "        return 'Unknown'\n",
        "\n",
        "    # Convert text to lowercase to handle case inconsistencies (e.g., 'Text post' vs 'text post')\n",
        "    cat_lower = str(category).lower()\n",
        "\n",
        "    # Now, check for keywords to group similar post types together\n",
        "    if 'gm' in cat_lower:\n",
        "        return 'GM Post'\n",
        "    elif 'gn' in cat_lower:\n",
        "        return 'GN Post'\n",
        "    elif 'quote' in cat_lower:\n",
        "        return 'Quote Post'\n",
        "    elif 'text' in cat_lower:\n",
        "        return 'Text Post'\n",
        "    elif 'space' in cat_lower:\n",
        "        return 'X Space'\n",
        "    elif 'ga' in cat_lower:\n",
        "        return 'GA Post'\n",
        "    # This is a catch-all for any other specific types we didn't define a rule for\n",
        "    else:\n",
        "        return 'Misc Post'\n",
        "\n",
        "# Use the .apply() method to run our custom function on every row of the 'temp_category' column\n",
        "master_df['post_category'] = master_df['temp_category'].apply(standardize_post_type)\n",
        "\n",
        "print(\"--- Step 2 Complete: Created a single, clean 'post_category' column. ---\")\n",
        "\n",
        "\n",
        "# Step 3: Final Cleanup of the DataFrame\n",
        "# Now that we have our master 'post_category', we can drop the old, messy columns to tidy up.\n",
        "columns_to_drop = ['post_type', 'post_format', 'post_type_1', 'temp_category']\n",
        "master_df = master_df.drop(columns=columns_to_drop)\n",
        "\n",
        "print(\"--- Step 3 Complete: Dropped the old, messy columns. ---\")\n",
        "\n",
        "\n",
        "# Step 4: Verification\n",
        "# Let's look at the final results to confirm our work.\n",
        "print(\"\\n--- FINAL VERIFICATION ---\")\n",
        "print(\"\\nValue Counts for our clean 'post_category' column:\")\n",
        "print(master_df['post_category'].value_counts())\n",
        "\n",
        "print(\"\\nHead of our final, cleaned DataFrame:\")\n",
        "print(master_df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "DBR9jMariQoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df = master_df.drop('notes', axis=1)\n",
        "print(master_df.head())"
      ],
      "metadata": {
        "id": "KyktbFlukTPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the categorical columns that still have missing values\n",
        "# Based on our diagnostic, these are the main ones (excluding 'post_text' for now)\n",
        "cols_to_fill = [\n",
        "    'image_attached_',\n",
        "    'control',\n",
        "    'image_theme',\n",
        "    'ai_asuka_involved',\n",
        "    'in-group_activity_present',\n",
        "    'assumed_poster',\n",
        "    'comment_summary'\n",
        "]\n",
        "\n",
        "# Loop through the list of columns and fill any missing values with 'Unknown'\n",
        "for col in cols_to_fill:\n",
        "    if col in master_df.columns: # A safe check to make sure the column exists\n",
        "        master_df[col] = master_df[col].fillna('Unknown')\n",
        "\n",
        "# --- Final Verification ---\n",
        "# Let's run our missing value check one last time to confirm our work.\n",
        "print(\"--- Final Missing Value Check ---\")\n",
        "print(master_df.isnull().sum())"
      ],
      "metadata": {
        "id": "NZUJz4YAlAFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Exploratory Analysis & Visualizations"
      ],
      "metadata": {
        "id": "jgaZ3EvUNUf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Average Impressions per Phase\n",
        "\n",
        "To get a high-level overview of the experiment's impact, we first analyze the average number of impressions per post for each of the three phases. The bar chart below clearly shows a significant spike in impressions during the 'Persona' phase, with a sustained \"halo effect\" into the 'Post' phase."
      ],
      "metadata": {
        "id": "_AJe51DSNVoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data for our specific plot\n",
        "# we will group our clean master_df by phase and calculate the mean of the impressions\n",
        "phase_impressions = master_df.groupby('phase')['impressions'].mean().reset_index()\n",
        "print(phase_impressions)"
      ],
      "metadata": {
        "id": "QF0exzs8W23H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# import in seaborn and its supporting library for visualization\n",
        "\n",
        "# we are going to make sure the names in our summary table are correct\n",
        "# (they might have been cleaned again during the load process)\n",
        "print(phase_impressions['phase'].unique())\n",
        "\n",
        "#create a list that defines the correct chronological order\n",
        "phase_order = ['Control', 'Persona', 'Post']\n",
        "\n",
        "#create the bar plot with the correct order of phases\n",
        "sns.catplot(x='phase', y='impressions', data=phase_impressions, kind='bar', order=phase_order)\n",
        "\n",
        "#adding a clear, story-driven title\n",
        "plt.suptitle('Average Impressions Spiked During Persona Phase', y=1.03)\n",
        "\n",
        "#adding the axis labels for a clearer story\n",
        "plt.xlabel('Experiment Phase')\n",
        "plt.ylabel('Average Impressions per Post')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D_5fg8oSXVuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Relationship Between Impressions and Engagements by Phase\n",
        "\n",
        "To understand the dynamics of engagement, we can plot impressions versus total engagements for each post. The faceted scatter plot below shows this relationship for each of the three experiment phases. We can observe a generally positive correlation, but the density and spread of the data points differ noticeably across the phases, particularly in the 'Persona' phase which saw higher-impression posts."
      ],
      "metadata": {
        "id": "FAVYBiKhN052"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we are making a relplot that shows the relationship between impressions and\n",
        "# engagements per phase\n",
        "\n",
        "#create a list that defines the correct chronological order\n",
        "phase_order = ['Control', 'Persona', 'Post']\n",
        "\n",
        "# setting up the palette for the scatter plot for easier visualization\n",
        "sns.set_palette('plasma')\n",
        "\n",
        "\n",
        "# create the rel plot with the correct order of phases, impressions and\n",
        "# engagements\n",
        "sns.relplot(x='impressions', y='engagements', data=master_df, kind='scatter', col_order=phase_order, col='phase',alpha=0.5)\n",
        "\n",
        "#adding a clear, story-driven title\n",
        "plt.suptitle('Engagements Followed Impressions across all 3 phases ', y=1.03)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VLWEp3iLbWty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Deeper Dive into Engagement Rates\n",
        "\n",
        "To understand the nuances of the engagement rate, a heatmap allows us to compare the average rates across every post category and experiment phase simultaneously. The heatmap below reveals a key insight: while the 'Persona' phase drove higher impressions, the 'Control' phase actually had the highest engagement rates for its core post types (GM/GN), indicating a more dedicated, albeit smaller, audience."
      ],
      "metadata": {
        "id": "sHDFgsuGOAtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Assuming master_df is our clean DataFrame from the previous steps)\n",
        "\n",
        "print(\"--- Preparing Data for the Heatmap ---\")\n",
        "\n",
        "# First, let's make sure our phases are in the correct chronological order\n",
        "# We can do this by converting the 'phase' column to a categorical data type\n",
        "phase_order = ['Control', 'Persona', 'Post']\n",
        "master_df['phase'] = pd.Categorical(master_df['phase'], categories=phase_order, ordered=True)\n",
        "\n",
        "# Now, pivot the data to create the grid format needed for a heatmap\n",
        "heatmap_pivot = master_df.pivot_table(\n",
        "    values='engagement_rate__pct',  # The values to fill the grid\n",
        "    index='post_category',         # The rows of the grid\n",
        "    columns='phase'                # The columns of the grid\n",
        ")\n",
        "\n",
        "# 1. Define a more logical order for our post categories (the rows)\n",
        "category_order = ['GM Post', 'GN Post', 'GA Post', 'Text Post', 'Quote Post', 'X Space', 'Misc Post']\n",
        "\n",
        "# 2. Re-order the pivot table's index to match our logical order\n",
        "heatmap_pivot = heatmap_pivot.reindex(category_order)\n",
        "\n",
        "# 3. Fill any missing values with 0 for a cleaner visual\n",
        "heatmap_pivot_clean = heatmap_pivot.fillna(0)\n",
        "\n",
        "\n",
        "# --- The New, Improved Heatmap ---\n",
        "\n",
        "# Make the figure a bit bigger to give it space\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "# Plot the cleaned and re-ordered pivot table\n",
        "sns.heatmap(data=heatmap_pivot_clean,\n",
        "            annot=True,\n",
        "            fmt=\".1f\",\n",
        "            cmap='viridis')\n",
        "\n",
        "# Add a clearer title and labels\n",
        "plt.title('Average Engagement Rate (%) by Phase and Post Type', fontsize=16)\n",
        "plt.xlabel('Experiment Phase')\n",
        "plt.ylabel('Post Category')"
      ],
      "metadata": {
        "id": "TGUUZS87qkWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Follower Growth Analysis\n",
        "\n",
        "One of the primary outcomes of the experiment was the rapid follower growth observed during the 'Persona' phase. This section analyzes the follower trend over the entire observation period. The data, based on snapshots from X Analytics and later corrected, shows that the vast majority of the account's growth occurred during the 7-day 'Persona' phase."
      ],
      "metadata": {
        "id": "NnSOzURsPZdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the URL to the raw CSV file on Github\n",
        "github_url = 'https://raw.githubusercontent.com/YamaMaki/aiasuka-data-project/refs/heads/main/follower_growth%20-%20Sheet1.csv'\n",
        "\n",
        "#allow pandas to read the csv from the url\n",
        "followers_df = pd.read_csv(github_url)\n",
        "\n",
        "print(\"successfully loaded data from Github!\")\n",
        "print(followers_df.head())\n",
        "\n",
        "# Convert 'Date' column to datetime objects for proper plotting\n",
        "followers_df['Date'] = pd.to_datetime(followers_df['Date'])\n",
        "\n",
        "# Convert 'Followers' column to a numeric type (float or int)\n",
        "followers_df['Followers'] = followers_df['Followers'].str.replace(',', '').astype(float)\n",
        "\n",
        "# --- The Investigation ---\n",
        "# We are checking for columns and values inside to make sure that its cleaned\n",
        "print(\"Columns found in your CSV file:\")\n",
        "print(followers_df.columns)\n",
        "\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "sns.set_palette('viridis')\n",
        "\n",
        "sns.relplot(x='Date', y='Followers', data=followers_df, kind='line', marker='o')\n",
        "plt.title('Follower Growth Over AiAsuka Experiment')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Followers')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vT1ENiKz7dz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Statistical Validation\n",
        "\n",
        "To ensure the observed differences in the data were not due to random chance, a series of statistical tests were performed. We used independent t-tests to compare the mean engagement rates between pairs of phases and a one-way ANOVA to compare the mean impressions across all three phases. The significance level (alpha) was set at 0.05."
      ],
      "metadata": {
        "id": "04_3ny81OzSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "print(\"--- Running Full Statistical Validation on Engagement Rates ---\")\n",
        "\n",
        "# --- 1. Prepare Data Samples for All Phases ---\n",
        "control_rates = master_df[master_df['phase'] == 'Control']['engagement_rate__pct']\n",
        "persona_rates = master_df[master_df['phase'] == 'Persona']['engagement_rate__pct']\n",
        "post_rates = master_df[master_df['phase'] == 'Post']['engagement_rate__pct']\n",
        "\n",
        "# --- 2. Run All Three T-Tests ---\n",
        "stat_cvp, p_value_cvp = ttest_ind(control_rates, persona_rates)\n",
        "stat_pvp, p_value_pvp = ttest_ind(persona_rates, post_rates)\n",
        "stat_cvsp, p_value_cvsp = ttest_ind(control_rates, post_rates)\n",
        "\n",
        "# --- 3. Print a Clean Summary of Results ---\n",
        "print(\"\\n--- T-Test Results Summary (alpha = 0.05) ---\")\n",
        "\n",
        "# Comparison 1: Control vs. Persona\n",
        "print(f\"\\n1. Control Phase vs. Persona Phase:\")\n",
        "print(f\"   P-value: {p_value_cvp:.4f}\")\n",
        "if p_value_cvp < 0.05:\n",
        "    print(\"   Result: The difference IS statistically significant.\")\n",
        "else:\n",
        "    print(\"   Result: The difference IS NOT statistically significant.\")\n",
        "\n",
        "# Comparison 2: Persona vs. Post\n",
        "print(f\"\\n2. Persona Phase vs. Post Phase:\")\n",
        "print(f\"   P-value: {p_value_pvp:.4f}\")\n",
        "if p_value_pvp < 0.05:\n",
        "    print(\"   Result: The difference IS statistically significant.\")\n",
        "else:\n",
        "    print(\"   Result: The difference IS NOT statistically significant.\")\n",
        "\n",
        "# Comparison 3: Control vs. Post\n",
        "print(f\"\\n3. Control Phase vs. Post Phase:\")\n",
        "print(f\"   P-value: {p_value_cvsp:.4f}\")\n",
        "if p_value_cvsp < 0.05:\n",
        "    print(\"   Result: The difference IS statistically significant.\")\n",
        "else:\n",
        "    print(\"   Result: The difference IS NOT statistically significant.\")\n"
      ],
      "metadata": {
        "id": "gEfoTCXKuTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "# --- Prepare the Data Samples for the ANOVA Test ---\n",
        "\n",
        "# Create a Series containing all impressions from the 'Control' phase\n",
        "control_impressions = master_df[master_df['phase'] == 'Control']['impressions']\n",
        "\n",
        "# Create a Series containing all impressions from the 'Persona' phase\n",
        "persona_impressions = master_df[master_df['phase'] == 'Persona']['impressions']\n",
        "\n",
        "# Create a Series containing all impressions from the 'Post' phase\n",
        "post_impressions = master_df[master_df['phase'] == 'Post']['impressions']\n",
        "\n",
        "\n",
        "# --- Verify our samples ---\n",
        "print(\"--- Data Ready for ANOVA Test ---\")\n",
        "print(f\"Number of 'Control' samples: {len(control_impressions)}\")\n",
        "print(f\"Average Control Impressions: {control_impressions.mean():.0f}\")\n",
        "\n",
        "print(f\"\\nNumber of 'Persona' samples: {len(persona_impressions)}\")\n",
        "print(f\"Average Persona Impressions: {persona_impressions.mean():.0f}\")\n",
        "\n",
        "print(f\"\\nNumber of 'Post' samples: {len(post_impressions)}\")\n",
        "print(f\"Average Post Impressions: {post_impressions.mean():.0f}\")\n",
        "\n",
        "#run the ANOVA test:\n",
        "f_oneway(control_impressions, persona_impressions, post_impressions)\n"
      ],
      "metadata": {
        "id": "znkN7PSCxVcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Load the Data ---\n",
        "followers_df = pd.read_csv('follower_growth - Sheet1.csv')\n",
        "\n",
        "# --- 2. Initial Inspection ---\n",
        "print(\"--- Follower Data Loaded Successfully ---\")\n",
        "print(\"First 5 rows:\")\n",
        "print(followers_df.head())\n",
        "\n",
        "print(\"\\n--- Data Info ---\")\n",
        "# Let's check the column names and data types (Dtypes)\n",
        "followers_df.info()"
      ],
      "metadata": {
        "id": "amWOSxNDxbuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary Statistics Table\n",
        "\n",
        "To provide a clear, high-level overview of the key performance indicators for each phase, the following summary table was generated from the clean dataset. This table serves as the primary source of truth for the metrics cited throughout this analysis."
      ],
      "metadata": {
        "id": "dteJAqsbPvd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this code block will calculate the key summary stats for each phase\n",
        "# First, we will group by the 'phase column and aggregate our metrics\n",
        "phase_summary = master_df.groupby('phase').agg(\n",
        "    total_impressions=('impressions', 'sum'),\n",
        "    total_engagements=('engagements', 'sum'),\n",
        "    average_engagement_rate=('engagement_rate__pct', 'mean')\n",
        ")\n",
        "\n",
        "# we are going to format the engagement rate to be a percentage, rounded to 2\n",
        "# decimal places\n",
        "phase_summary['average_engagement_rate'] = (phase_summary['average_engagement_rate']).round(2)\n",
        "\n",
        "print(\"--- Validation of Key Metrics from Cleaned Data ---\")\n",
        "print(phase_summary)"
      ],
      "metadata": {
        "id": "JQst8sQyEZWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Conclusion & Final Thoughts\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "This analysis, validated with a cleaned and unified dataset, confirms the core findings of the Aiasuka experiment:\n",
        "\n",
        "* **Finding 1:** The introduction of the synthetic \"Persona\" generated a massive, statistically significant increase in **impressions** and **follower growth**, proving the effectiveness of this strategy for capturing audience attention in the short term.\n",
        "* **Finding 2:** However, this growth in reach came at the cost of engagement *quality*. The average **engagement rate** was highest in the authentic \"Control\" phase, and the difference between the Control and Persona phases was not statistically significant.\n",
        "* **Finding 3:** The end of the experiment in the \"Post\" phase caused a severe, statistically significant **drop in engagement rates**, demonstrating the fragile and unsustainable nature of the parasocial bonds formed with the synthetic persona.\n",
        "\n",
        "### Ethical Implications & The \"Synthetic Femme\" Problem\n",
        "\n",
        "7. Insights\n",
        "7.1 Gender Bias Amplifies Virality\n",
        "Aiasukaâ€™s +47% Impression spike (15,069 vs. 10,255) and ~700+ follower gain, driven by selfies and $SOL giveaways (e.g., April 22 GM, 33.91%), reflect gender bias. Personaâ€™s 26.70% Engagement Rate is lower than Controlâ€™s 32.21% (e.g., 69.52% GM), but GM (39.13%) and GN (37.75%) outperform Controlâ€™s Misc (28.07%), showing synthetic femininityâ€™s strength.\n",
        "\n",
        "7.2 Parasocial Drift Spectrum\n",
        "Persona-phase replies (e.g., â€œgoodmorning babeâ€) showed emotional investment, with flirty, supportive, and begging comments (e.g., April 22 GM, 79 Replies). Controlâ€™s neutral replies (e.g., April 15 GM, 31 Replies) contrast with Post-phaseâ€™s superficial affirmations (e.g., â€œFacts ðŸ’¯â€). The April 23 bookend (9.18%, 72 Replies) reflects shock (e.g., â€œSO UR NOT A GIRLâ€), with ~60% of Persona followers disengaging emotionally.\n",
        "\n",
        "7.3 Engagement Trade-Off\n",
        "Controlâ€™s 32.21% Engagement Rate (e.g., 44.20% Misc â€œstory in 3 imagesâ€) reflects authentic Web3 appeal. Personaâ€™s 26.70% (e.g., 40.41% GN) and Postâ€™s 16.91% (e.g., 34.30% GM) show a trade-off: Aiasukaâ€™s GM (39.13%) outperformed Controlâ€™s Misc (28.07%), but Post-phase GM (24.12%) and â€œFacts ðŸ’¯â€ replies lack emotional depth.\n",
        "\n",
        "7.4 Halo Effect\n",
        "Post-phase Impressions (384.3 avg, 3247 max for bookend) and ~250 follower gain confirm Aiasukaâ€™s lasting visibility. The decline from 26.70% to 16.91% Engagement Rate and from Persona GM (39.13%) to Post GM (24.12%) shows fading emotional bonds, unlike Controlâ€™s consistent 32.21%.\n",
        "\n",
        "7.5 Authenticity vs. Perception\n",
        "Bookends (17.39%, 9.18%) underperformed Control (32.21%) and Persona (26.70%). Controlâ€™s Misc (28.07%) outperforms Personaâ€™s Misc (20.33%) and Postâ€™s Misc (14.27%), but slower Post-phase follower growth (~250 vs. ~700) confirms synthetic femininityâ€™s dominance.\n",
        "\n",
        "8. Post-Reveal Dynamics\n",
        "The Post phase shows a trajectory of disengagement:\n",
        "Immediate Shock (April 23): The bookend (9.18%, 72 Replies) reflects surprise (â€œSO UR NOT A GIRLâ€ @MxmetaX) and positivity (â€œHandsomeâ€). Lower Engagement Rate vs. Personaâ€™s 26.70% confirms Aiasukaâ€™s pull.\n",
        "\n",
        "Early Post-Phase (April 24â€“25): GM/GN posts (e.g., April 25 GM, 34.30%, 48 Replies; April 24 GN, 21.94%, 20 Replies) show strong engagement, driven by $SOL giveaways (e.g., April 24 GM, 24.80%, 66 Replies) and motivational content (e.g., April 25 Misc, 27.63%).\n",
        "\n",
        "Mid Post-Phase (April 26â€“27): GM/GN posts remain strong (e.g., April 27 GM, 26.95%, 29 Replies; April 27 GN, 21.64%, 21 Replies), but Misc posts vary (e.g., April 27 Misc, 22.73%, 9 Replies). Spiritual (e.g., April 27 Misc â€œPsalm 27:1â€) and community posts (@Teatimemeta) resonate, but lack Personaâ€™s intensity (e.g., April 22 GN, 40.41%).\n",
        "\n",
        "Giveaway Boost: Solana/Doge giveaways sustained engagement, but superficial replies signal limited connection.\n",
        "\n",
        "Trust Erosion: Skeptical and detached replies, with slower follower growth (~250 vs. ~700), highlight trust erosion risks. Community ties (@Teatimemeta, #Dogwarts) maintain moderate engagement.\n",
        "\n",
        "9. Ethical Warning: The Synthetic Femme Problem\n",
        "Aiasukaâ€™s 15,069 Impressions, 26.70% Engagement Rate, and ~700+ follower gain dwarf female creator benchmarks (5,000â€“8,000 Impressions, 10â€“15% Engagement Rates). Controlâ€™s 32.21% shows authentic appeal, but Postâ€™s 16.91% and â€œFacts ðŸ’¯â€ replies highlight risks:\n",
        "Attention Displacement: Synthetic personas dominate Web3â€™s attention economy.\n",
        "\n",
        "Trust Erosion: Detached replies (e.g., â€œPreach that wisdom kingâ€) and shock (e.g., â€œcatfish!!! LOLâ€) suggest synthetic personas exploit emotional investment.\n",
        "\n",
        "Stereotype Reinforcement: Aiasukaâ€™s idealized selfies perpetuate unattainable femininity.\n",
        "\n",
        "Algorithmic Bias: Personaâ€™s 5.26% Replies and ~60% follower growth amplified synthetic content, while Postâ€™s 4.33% reflects reduced favor.\n",
        "\n",
        "10. Mitigation Tactics\n",
        "Amplify real female creators via X Spaces or NFT collaborations, leveraging tools like Metaplex.\n",
        "\n",
        "Require AI personas to disclose artificiality.\n",
        "\n",
        "Advocate for X algorithmic audits.\n",
        "\n",
        "Educate Web3 on parasocial risks.\n",
        "\n",
        "11. Application for Brands\n",
        "Short-Term Visibility: Synthetic personas boost Impressions (15,069) and followers (~700 in 7 days).\n",
        "\n",
        "Hybrid Approach: Pair AI with real creators, as seen in April 27 Miscâ€™s influencer mentions.\n",
        "\n",
        "Metrics-Driven: Prioritize Replies (e.g., 79 for April 22 GM, 66 for April 24 GM).\n",
        "\n",
        "Long-Term Trust: Postâ€™s 16.91% Engagement Rate and â€œalgorithmic fillâ€ replies show synthetic personasâ€™ unsustainability, unlike Controlâ€™s 32.21%.\n",
        "\n",
        "### Final Thought\n",
        "\n",
        "The Aiasuka experiment highlights a critical tension in our increasingly digital world, demonstrating that while audiences may be drawn to idealized synthetic personas, the resulting connections are fragile and raise profound ethical questions about authenticity and trust online."
      ],
      "metadata": {
        "id": "4sKLpHeKQCrz"
      }
    }
  ]
}